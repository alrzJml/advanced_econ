{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_coint_rank, select_order\n",
    "\n",
    "from helper_functions import stock_prices, stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cointegration_params(df, verbose=False):\n",
    "    lag_order = select_order(df, maxlags=10, deterministic=\"ci\")\n",
    "    lag_order = lag_order.aic\n",
    "\n",
    "    rank_test = select_coint_rank(df, 0, lag_order, method=\"trace\",\n",
    "                              signif=0.05)\n",
    "\n",
    "    is_cointegrated = rank_test.test_stats[0] > rank_test.crit_vals[0]\n",
    "    if verbose:\n",
    "        print(rank_test.summary())\n",
    "    if not is_cointegrated:\n",
    "        return False, np.NaN, np.NAN\n",
    "    \n",
    "    model = VECM(df, deterministic=\"ci\",\n",
    "             k_ar_diff=lag_order,\n",
    "             coint_rank=rank_test.rank)\n",
    "    vecm_res = model.fit()\n",
    "\n",
    "    return True, vecm_res.beta, vecm_res.const_coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "file = pd.ExcelFile('../01_pair_trading/pairs_2023-01-13.xlsx')\n",
    "sheet_names = ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']\n",
    "for sheet in sheet_names:\n",
    "    df_tmp = pd.read_excel(file, sheet_name=sheet)\n",
    "    df = pd.concat([df, df_tmp])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groom(s):\n",
    "    s = s.replace('ي', 'ی')\n",
    "    s = s.replace('ك', 'ک')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "def is_normal_jb(x) -> bool:\n",
    "    test = stats.jarque_bera(x)\n",
    "    return test.pvalue > 0.05\n",
    "\n",
    "def is_normal_ad(x) -> bool:\n",
    "    test = stats.anderson(x)\n",
    "    return test.statistic < test.critical_values[2]\n",
    "\n",
    "def is_normal_crm(x) -> bool:\n",
    "    test = stats.cramervonmises(x, 'norm')\n",
    "    return test.pvalue > 0.05\n",
    "\n",
    "def is_normal_lil(x) -> bool:\n",
    "    test = lilliefors(x,  dist='norm')\n",
    "    return test[1] > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def ks_test(data, dist_name, alpha=0.01):\n",
    "    y, x = np.histogram(data, bins=100, density=True)\n",
    "    x = [(this + x[i + 1]) / 2.0 for i, this in enumerate(x[0:-1])]\n",
    "\n",
    "    dist = eval(\"scipy.stats.\"+ dist_name)\n",
    "    if (dist_name == \"nbinom\"):\n",
    "        p = np.mean(data)/(np.std(data)**2)\n",
    "        n = np.mean(data)*p/(1.0 - p)\n",
    "        if n<0 or p<0 or p>1:\n",
    "            return True, np.nan, np.nan, np.nan\n",
    "        param = (n, p)\n",
    "    else:\n",
    "        param = dist.fit(data)\n",
    "\n",
    "    dist_fitted = dist(*param)\n",
    "\n",
    "    ks_stat, ks_pval = stats.kstest(data, dist_fitted.cdf)\n",
    "    return (ks_pval < alpha), dist, param, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_dist(data, ticker1, ticker2, indice_path):\n",
    "\n",
    "    fitted_normal_methods = []\n",
    "    fitted_dists = []\n",
    "\n",
    "    normal_methods = [\"jb\", \"ad\", \"crm\", \"lil\"]\n",
    "    for method in normal_methods:\n",
    "        fn = eval(f\"is_normal_{method}\")\n",
    "        if fn(data):\n",
    "            fitted_normal_methods.append(method)\n",
    "        \n",
    "\n",
    "    options = [\"norm\", \"lognorm\", \"chi2\", \"t\", \"beta\", \"gamma\", \"weibull_min\", \"nbinom\"]\n",
    "\n",
    "    hs = plt.hist(data, bins=80, density=True, label=\"data\");\n",
    "    for dist_name in options:\n",
    "        is_h0_rejected, dist,  param, x =  ks_test(data, dist_name)\n",
    "        if is_h0_rejected:\n",
    "            continue\n",
    "        else:\n",
    "            fitted_dists.append(dist_name)\n",
    "            if dist_name == \"nbinom\":\n",
    "                h = plt.plot(x, dist.pmf(x, *param), label=dist_name);\n",
    "            else:\n",
    "                h = plt.plot(x, dist.pdf(x, *param), label=dist_name);\n",
    "\n",
    "    plt.title(f\"{ticker1} & {ticker2}\")\n",
    "    plt.legend();\n",
    "    plt.savefig(rf'{indice_path}/{ticker1} & {ticker2}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return fitted_normal_methods, fitted_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "PATH = r'./plots/'\n",
    "if os.path.exists(PATH):\n",
    "    shutil.rmtree(PATH)\n",
    "os.makedirs(PATH)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pairs = []\n",
    "for indice in ['Dow Jones', 'CAC 40', 'Dax']:\n",
    "    indice_path = PATH + indice\n",
    "    os.makedirs(indice_path)\n",
    "    \n",
    "    print(indice, '>>', flush=True)\n",
    "    df1 = df[df['indice']==indice]\n",
    "    tickers = stock_list.get_stock_list(index=indice)\n",
    "    isTSE = (indice == 'Teh50')\n",
    "    if isTSE:\n",
    "        tickers = [groom(x) for x in tickers]\n",
    "    data_historical = stock_prices.get_prices(tickers, isTSE)\n",
    "\n",
    "    for i in range(df1.shape[0]):\n",
    "        ticker1, ticker2, indice = df1.iloc[i]\n",
    "\n",
    "        data_historical1 = data_historical[[ticker1, ticker2]]\n",
    "\n",
    "        data_historical1 = data_historical1.dropna(how='all')\n",
    "        data = data_historical1[-interval:]\n",
    "\n",
    "        limitPer = len(data) * .85\n",
    "        data = data.dropna(thresh=limitPer, axis=1)\n",
    "\n",
    "        data = np.log(data)\n",
    "\n",
    "        data = data.dropna(how='any')\n",
    "\n",
    "        cols = data.columns\n",
    "\n",
    "        for i in range(len(cols)-1):\n",
    "            for j in range(i+1, len(cols)):\n",
    "                try:\n",
    "                    is_cointegrated, BJ2n, C0J2n = get_cointegration_params(data.dropna(how='any'))\n",
    "                except:\n",
    "                    continue\n",
    "                if not is_cointegrated:\n",
    "                    continue\n",
    "                \n",
    "                ecm = np.matmul(data, BJ2n) + C0J2n\n",
    "                x = ecm[0].values\n",
    "                fitted_normal_methods, fitted_dists = test_for_dist(x, ticker1, ticker2, indice_path)\n",
    "                pairs.append({\n",
    "                    'sym1': cols[i],\n",
    "                    'sym2': cols[j],\n",
    "                    'indice': indice,\n",
    "                    'fitted_normal_methods': fitted_normal_methods,\n",
    "                    'fitted_dists': fitted_dists\n",
    "                })\n",
    "\n",
    "\n",
    "filename = rf'./ecm_dists.xlsx'\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "df_errors = pd.DataFrame(pairs)\n",
    "for index, group_df in df_errors.groupby(\"indice\"):   \n",
    "    group_df.to_excel(writer, sheet_name=str(index),index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pairs)\n",
    "df.to_excel('./ecm_dists.xlsx')\n",
    "\n",
    "df = pd.read_excel('./ecm_dists.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_arr = []\n",
    "import ast\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    dists_arr = dists_arr + ast.literal_eval(row['fitted_dists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{x:dists_arr.count(x) for x in dists_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fitted_normal_methods.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Sep  6 2022, 23:16:16) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
