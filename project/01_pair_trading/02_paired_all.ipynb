{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shipping pair trading code from Matlab to Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importig Two helper functions from `./helper_functions`:\n",
    "\n",
    "- `stock_list`: This functions gets an index name (e.g. 'Dow Jones', 'CAC 40', 'DAX', 'Teh50') and returns the list of stocks in that index.\n",
    "\n",
    "- `stock_prices`: This functions recieves a list of tickers and returns a pandas dataframe containing prices of the corresponding tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import stock_list, stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Fucntions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the 521 trailing days of prices series. 126 last days will be the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsmpl=126\n",
    "\n",
    "interval = 521"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cointegration function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explain the code in 7 steps. The starting point of each step is commented in the code by the corresponding number:\n",
    "\n",
    "1. Importing required functions and classes.\n",
    "2. We define a function to test the cointegration relation and return the parameters if the relation holds. The function gets a two-column dataframe consisting of prices series for two tickers and a `verbose` flag that will make the function to print extra information if set to True.\n",
    "3. The best lag order for the Cointegration test is determined using `select_order` function.\n",
    "4. We try to select the best cointegratino rank for our two series. The `select_coint_rank` functions uses the Johansen Test internally.\n",
    "5. If the stat of the test is greater than the critical value, We can conclude that the two series are cointegrated.\n",
    "6. If two series are not cointegrated, we return False as the test result and NaN as the parameters of VECM model.\n",
    "7. To find the VECM parameters, We use the `VECM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_coint_rank, select_order\n",
    "\n",
    "# 2\n",
    "def get_cointegration_params(df, verbose=False):\n",
    "    # 3\n",
    "    lag_order = select_order(df, maxlags=10, deterministic=\"ci\")\n",
    "    lag_order = lag_order.aic\n",
    "    # 4\n",
    "    rank_test = select_coint_rank(df, 0, lag_order, method=\"trace\",\n",
    "                              signif=0.05)\n",
    "\n",
    "    # 5\n",
    "    is_cointegrated = rank_test.test_stats[0] > rank_test.crit_vals[0]\n",
    "    if verbose:\n",
    "        print(rank_test.summary())\n",
    "\n",
    "    # 6\n",
    "    if not is_cointegrated:\n",
    "        return False, np.NaN, np.NAN\n",
    "    \n",
    "    # 7\n",
    "    model = VECM(df, deterministic=\"ci\",\n",
    "             k_ar_diff=lag_order,\n",
    "             coint_rank=rank_test.rank)\n",
    "    vecm_res = model.fit()\n",
    "\n",
    "    return True, vecm_res.beta, vecm_res.const_coint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function Will convert the arabic glyphs to standard farsi glyphs. This will be helpful while looking Tehran50 tickers up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groom(s):\n",
    "    s = s.replace('ي', 'ی')\n",
    "    s = s.replace('ك', 'ک')\n",
    "    return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppressing all the warnings in order to have a clear output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Trading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explain the code in 7 steps. The starting point of each step is commented in the code by the corresponding number:\n",
    "\n",
    "1. We Will save all the plots in the `./plots/{index_name}/` directory. We will remove and recreate the directory each time we run the code.\n",
    "2. We write a for loop that itterates over four indices: 'Dow Jones', 'CAC 40', 'Dax', 'Teh50'\n",
    "3. We get the list of tickers in the given indice and then get the price of all the tickers in that index. We split the data into train and test.\n",
    "4. For each pair of tickers, we test for cointegration using `get_cointegration_params` function and if They are in fact cointegrated, we save them in the `pairs` list.\n",
    "5. We compute the ECM of the cointegrated pairs and try to extract Long/Short signals from them.\n",
    "6. We plot 4 graphs: prices of the tickers, The cointegratino Relatino, Out of Sample Cumulative Return and In Sample Cumulative Return\n",
    "7. We save the cointegrates pairs in an excel file to use it in other part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  30 of 30 completed\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OCBI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AZSEY: No data found, symbol may be delisted\n",
      "Teh50"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import shutil\n",
    "PATH = r'./plots/'\n",
    "if os.path.exists(PATH):\n",
    "    shutil.rmtree(PATH)\n",
    "os.makedirs(PATH)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "# 2\n",
    "for indice in ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']:\n",
    "    print(indice, sep=' ', end='', flush=True)\n",
    "\n",
    "    # Creating the required directories to save the plots\n",
    "    PATH = rf'./plots/{indice}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    # 3\n",
    "    tickers = stock_list.get_stock_list(index=indice)\n",
    "    symbolsnum = len(tickers)\n",
    "    isTSE = (indice == 'Teh50')\n",
    "    if isTSE:\n",
    "        tickers = [groom(x) for x in tickers]\n",
    "    data_historical = stock_prices.get_prices(tickers, is_tse=isTSE)\n",
    "    data_historical = data_historical.dropna(how='all')\n",
    "    data = data_historical[-interval:]\n",
    "    limitPer = len(data) * .85\n",
    "    data = data.dropna(thresh=limitPer, axis=1)\n",
    "    data = np.log(data)\n",
    "    data_train = data[:-testsmpl]\n",
    "    data_test = data[-testsmpl:]\n",
    "\n",
    "    # 4\n",
    "    cols = data_train.columns\n",
    "    for i in range(len(cols)-1):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            df_train = data_train[[cols[i], cols[j]]].copy()\n",
    "            df_test = data_test[[cols[i], cols[j]]].copy()\n",
    "            try:\n",
    "                is_cointegrated, BJ2n, C0J2n = get_cointegration_params(df_train.dropna(how='any'))\n",
    "            except:\n",
    "                continue\n",
    "            if not is_cointegrated:\n",
    "                continue\n",
    "            pairs.append({\n",
    "                'sym1': cols[i],\n",
    "                'sym2': cols[j],\n",
    "                'indice': indice\n",
    "            })\n",
    "\n",
    "            # 5\n",
    "            cointRinsmpl = np.matmul(df_train, BJ2n) + C0J2n\n",
    "            cointRtest = np.matmul(df_test, BJ2n) + C0J2n\n",
    "\n",
    "            scointR = np.std(cointRinsmpl)[0]\n",
    "            mcointR = np.mean(cointRinsmpl)[0]\n",
    "\n",
    "            cointR = cointRinsmpl.append(cointRtest)\n",
    "            longs = cointR<=mcointR-2*scointR\n",
    "            shorts=cointR>=mcointR+2*scointR; \n",
    "            exitLongs=cointR>=mcointR-1*scointR; \n",
    "            exitShorts=cointR<=mcointR+1*scointR; \n",
    "\n",
    "            positionsL = np.zeros((cointR.shape[0], 2))\n",
    "            positionsS = np.zeros((cointR.shape[0], 2))\n",
    "\n",
    "            positionsL = pd.DataFrame(positionsL)\n",
    "            positionsS = pd.DataFrame(positionsS)\n",
    "\n",
    "\n",
    "            positionsL.iloc[positionsL[longs.values].index, 0] = 1\n",
    "            positionsL.iloc[positionsL[longs.values].index, 1] = -1\n",
    "            positionsL.iloc[positionsL[exitLongs.values].index, 0] = 0\n",
    "            positionsL.iloc[positionsL[exitLongs.values].index, 1] = 0\n",
    "\n",
    "            positionsS.iloc[positionsS[shorts.values].index, 0] = -1\n",
    "            positionsS.iloc[positionsS[shorts.values].index, 1] = 1\n",
    "            positionsS.iloc[positionsS[exitShorts.values].index, 0] = 0\n",
    "            positionsS.iloc[positionsS[exitShorts.values].index, 1] = 0\n",
    "\n",
    "            positions = positionsL + positionsS\n",
    "\n",
    "            yret = np.log(df_train.append(df_test)).diff()\n",
    "            yret = yret[1:]\n",
    "\n",
    "            pnl=(\n",
    "            positions[0:-1][0] * yret[yret.columns[0]].values \n",
    "            - BJ2n[1][0]*positions[0:-1][1]*yret[yret.columns[1]].values\n",
    "            )\n",
    "\n",
    "            rsuminsmpl = np.cumsum(pnl[:-df_test.shape[0]])\n",
    "            rsumtest = np.cumsum(pnl[-df_test.shape[0]:])\n",
    "\n",
    "            ShrpRatinsmpl = np.sqrt(252)*np.mean(pnl[:-df_test.shape[0]])/np.std(pnl[:-df_test.shape[0]])\n",
    "            ShrpRatiTest = np.sqrt(252)*np.mean(pnl[-df_test.shape[0]:])/np.std(pnl[-df_test.shape[0]:])\n",
    "\n",
    "            # 6\n",
    "            ticker1, ticker2 = df_train.columns\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "            axs[0, 0].plot(df_train[ticker1])\n",
    "            axs[0, 0].plot(df_test[ticker1])\n",
    "            axs[0, 0].plot(df_train[ticker2])\n",
    "            axs[0, 0].plot(df_test[ticker2])\n",
    "            axs[0, 0].set_title(f'Pair Prices for {ticker1} and {ticker2}')\n",
    "            axs[0, 0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "            axs[0, 1].plot(cointR[:df_train.shape[0]])\n",
    "            axs[0, 1].plot(cointR[-df_test.shape[0]:])\n",
    "            axs[0, 1].set_title(f'Cointegrating Relations for {ticker1} and {ticker2}')\n",
    "            axs[0, 1].plot(cointR.index, [mcointR - 2*scointR]*cointR.shape[0])\n",
    "            axs[0, 1].plot(cointR.index, [mcointR + 2*scointR]*cointR.shape[0])\n",
    "            axs[0, 1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "            axs[1, 0].plot(df_test.index, rsumtest)\n",
    "            axs[1, 0].set_title(f'Out of Sample Cumulative Return for Pair {ticker1} and {ticker2}')\n",
    "\n",
    "            axs[1, 1].plot(df_train.index[1:], rsuminsmpl)\n",
    "            axs[1, 1].set_title(f'In Sample Cumulative Return for Pair {ticker1} and {ticker2}');\n",
    "            axs[1, 1].tick_params(axis='x', rotation=15);\n",
    "\n",
    "            fig.subplots_adjust(hspace=.3);\n",
    "\n",
    "            fig.savefig(rf'./plots/{indice}/cointr_{ticker1}_{ticker2}');\n",
    "            plt.close()\n",
    "\n",
    "# 7\n",
    "import datetime\n",
    "filename = rf'./pairs_{str(datetime.datetime.now().date())}.xlsx'\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "df_pairs = pd.DataFrame(pairs)\n",
    "for index, group_df in df_pairs.groupby(\"indice\"):   \n",
    "    group_df.to_excel(writer, sheet_name=str(index),index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teh50        164\n",
       "CAC 40       145\n",
       "Dax          134\n",
       "Dow Jones     66\n",
       "Name: indice, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs.indice.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Sep  6 2022, 23:16:16) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
