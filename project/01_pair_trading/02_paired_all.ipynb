{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import stock_list, stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "testsmpl=126\n",
    "interval = 252*3\n",
    "\n",
    "interval = 521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_coint_rank, select_order\n",
    "\n",
    "def get_cointegration_params(df, verbose=False):\n",
    "    lag_order = select_order(df, maxlags=10, deterministic=\"ci\")\n",
    "    lag_order = lag_order.aic\n",
    "\n",
    "    rank_test = select_coint_rank(df, 0, lag_order, method=\"trace\",\n",
    "                              signif=0.05)\n",
    "\n",
    "    is_cointegrated = rank_test.test_stats[0] > rank_test.crit_vals[0]\n",
    "    if verbose:\n",
    "        print(rank_test.summary())\n",
    "    if not is_cointegrated:\n",
    "        return False, np.NaN, np.NAN\n",
    "    \n",
    "    model = VECM(df, deterministic=\"ci\",\n",
    "             k_ar_diff=lag_order,\n",
    "             coint_rank=rank_test.rank)\n",
    "    vecm_res = model.fit()\n",
    "\n",
    "    return True, vecm_res.beta, vecm_res.const_coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groom(s):\n",
    "    s = s.replace('ي', 'ی')\n",
    "    s = s.replace('ك', 'ک')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  30 of 30 completed\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OCBI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AZSEY: No data found, symbol may be delisted\n",
      "Teh50"
     ]
    }
   ],
   "source": [
    "PATH = r'./plots/'\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for indice in ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']:\n",
    "    print(indice, sep=' ', end='', flush=True)\n",
    "    PATH = rf'./plots/{indice}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    tickers = stock_list.get_stock_list(index=indice)\n",
    "    symbolsnum = len(tickers)\n",
    "\n",
    "    isTSE = (indice == 'Teh50')\n",
    "    if isTSE:\n",
    "        tickers = [groom(x) for x in tickers]\n",
    "\n",
    "    data_historical = stock_prices.get_prices(tickers, is_tse=isTSE)\n",
    "    data_historical = data_historical.dropna(how='all')\n",
    "    data = data_historical[-interval:]\n",
    "\n",
    "    limitPer = len(data) * .85\n",
    "    data = data.dropna(thresh=limitPer, axis=1)\n",
    "\n",
    "    data = np.log(data)\n",
    "\n",
    "    data_train = data[:-testsmpl]\n",
    "    data_test = data[-testsmpl:]\n",
    "\n",
    "    cols = data_train.columns\n",
    "    for i in range(len(cols)-1):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            df_train = data_train[[cols[i], cols[j]]].copy()\n",
    "            df_test = data_test[[cols[i], cols[j]]].copy()\n",
    "            try:\n",
    "                is_cointegrated, BJ2n, C0J2n = get_cointegration_params(df_train.dropna(how='any'))\n",
    "            except:\n",
    "                continue\n",
    "            if not is_cointegrated:\n",
    "                continue\n",
    "            pairs.append({\n",
    "                'sym1': cols[i],\n",
    "                'sym2': cols[j],\n",
    "                'indice': indice\n",
    "            })\n",
    "\n",
    "            cointRinsmpl = np.matmul(df_train, BJ2n) + C0J2n\n",
    "            cointRtest = np.matmul(df_test, BJ2n) + C0J2n\n",
    "\n",
    "            scointR = np.std(cointRinsmpl)[0]\n",
    "            mcointR = np.mean(cointRinsmpl)[0]\n",
    "\n",
    "            cointR = cointRinsmpl.append(cointRtest)\n",
    "            longs = cointR<=mcointR-2*scointR\n",
    "            shorts=cointR>=mcointR+2*scointR; \n",
    "            exitLongs=cointR>=mcointR-1*scointR; \n",
    "            exitShorts=cointR<=mcointR+1*scointR; \n",
    "\n",
    "            positionsL = np.zeros((cointR.shape[0], 2))\n",
    "            positionsS = np.zeros((cointR.shape[0], 2))\n",
    "\n",
    "            positionsL = pd.DataFrame(positionsL)\n",
    "            positionsS = pd.DataFrame(positionsS)\n",
    "\n",
    "\n",
    "            positionsL.iloc[positionsL[longs.values].index, 0] = 1\n",
    "            positionsL.iloc[positionsL[longs.values].index, 1] = -1\n",
    "            positionsL.iloc[positionsL[exitLongs.values].index, 0] = 0\n",
    "            positionsL.iloc[positionsL[exitLongs.values].index, 1] = 0\n",
    "\n",
    "            positionsS.iloc[positionsS[shorts.values].index, 0] = -1\n",
    "            positionsS.iloc[positionsS[shorts.values].index, 1] = 1\n",
    "            positionsS.iloc[positionsS[exitShorts.values].index, 0] = 0\n",
    "            positionsS.iloc[positionsS[exitShorts.values].index, 1] = 0\n",
    "\n",
    "            positions = positionsL + positionsS\n",
    "\n",
    "            yret = np.log(df_train.append(df_test)).diff()\n",
    "            yret = yret[1:]\n",
    "\n",
    "            pnl=(\n",
    "            positions[0:-1][0] * yret[yret.columns[0]].values \n",
    "            - BJ2n[1][0]*positions[0:-1][1]*yret[yret.columns[1]].values\n",
    "            )\n",
    "\n",
    "            rsuminsmpl = np.cumsum(pnl[:-df_test.shape[0]])\n",
    "            rsumtest = np.cumsum(pnl[-df_test.shape[0]:])\n",
    "\n",
    "            ShrpRatinsmpl = np.sqrt(252)*np.mean(pnl[:-df_test.shape[0]])/np.std(pnl[:-df_test.shape[0]])\n",
    "            ShrpRatiTest = np.sqrt(252)*np.mean(pnl[-df_test.shape[0]:])/np.std(pnl[-df_test.shape[0]:])\n",
    "\n",
    "            \n",
    "            ticker1, ticker2 = df_train.columns\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "            axs[0, 0].plot(df_train[ticker1])\n",
    "            axs[0, 0].plot(df_test[ticker1])\n",
    "            axs[0, 0].plot(df_train[ticker2])\n",
    "            axs[0, 0].plot(df_test[ticker2])\n",
    "            axs[0, 0].set_title(f'Pair Prices for {ticker1} and {ticker2}')\n",
    "            axs[0, 0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "            axs[0, 1].plot(cointR[:df_train.shape[0]])\n",
    "            axs[0, 1].plot(cointR[-df_test.shape[0]:])\n",
    "            axs[0, 1].set_title(f'Cointegrating Relations for {ticker1} and {ticker2}')\n",
    "            axs[0, 1].plot(cointR.index, [mcointR - 2*scointR]*cointR.shape[0])\n",
    "            axs[0, 1].plot(cointR.index, [mcointR + 2*scointR]*cointR.shape[0])\n",
    "            axs[0, 1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "            axs[1, 0].plot(df_test.index, rsumtest)\n",
    "            axs[1, 0].set_title(f'Out of Sample Cumulative Return for Pair {ticker1} and {ticker2}')\n",
    "\n",
    "            axs[1, 1].plot(df_train.index[1:], rsuminsmpl)\n",
    "            axs[1, 1].set_title(f'In Sample Cumulative Return for Pair {ticker1} and {ticker2}');\n",
    "            axs[1, 1].tick_params(axis='x', rotation=15);\n",
    "\n",
    "            fig.subplots_adjust(hspace=.3);\n",
    "\n",
    "            fig.savefig(rf'./plots/{indice}/cointr_{ticker1}_{ticker2}');\n",
    "            plt.close()\n",
    "\n",
    "import datetime\n",
    "filename = rf'./pairs_{str(datetime.datetime.now().date())}.xlsx'\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "df_pairs = pd.DataFrame(pairs)\n",
    "for index, group_df in df_pairs.groupby(\"indice\"):   \n",
    "    group_df.to_excel(writer, sheet_name=str(index),index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Sep  6 2022, 23:16:16) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
