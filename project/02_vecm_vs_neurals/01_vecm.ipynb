{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECM Forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importig Two helper functions from `./helper_functions`:\n",
    "\n",
    "- `stock_list`: This functions gets an index name (e.g. 'Dow Jones', 'CAC 40', 'DAX', 'Teh50') and returns the list of stocks in that index.\n",
    "\n",
    "- `stock_prices`: This functions recieves a list of tickers and returns a pandas dataframe containing prices of the corresponding tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import stock_prices, stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Fucntions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the 521 trailing days of prices series. 126 last days will be the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsmpl=126\n",
    "\n",
    "interval = 521"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cointegration function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Function Works exactly like the `get_cointegration_params` function in the previous project (i.e. 01_pair_trading).\n",
    "\n",
    "The only diffrence is that it returns lag_order and rank of the cointegration test. The returned values will be used to build a VECM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_coint_rank, select_order\n",
    "\n",
    "def get_cointegration_params(df, verbose=False):\n",
    "    lag_order = select_order(df, maxlags=10, deterministic=\"ci\")\n",
    "    lag_order = lag_order.aic\n",
    "\n",
    "    rank_test = select_coint_rank(df, 0, lag_order, method=\"trace\",\n",
    "                              signif=0.05)\n",
    "\n",
    "    is_cointegrated = rank_test.test_stats[0] > rank_test.crit_vals[0]\n",
    "    if verbose:\n",
    "        print(rank_test.summary())\n",
    "    if not is_cointegrated:\n",
    "        return False, np.NaN, np.NAN\n",
    "    \n",
    "    model = VECM(df, deterministic=\"ci\",\n",
    "             k_ar_diff=lag_order,\n",
    "             coint_rank=rank_test.rank)\n",
    "    vecm_res = model.fit()\n",
    "\n",
    "    return True, lag_order, rank_test.rank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the list of cointegrated tickers from the output of the previous project (i.e. 01_pair_trading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "file = pd.ExcelFile('../01_pair_trading/pairs_2023-01-15.xlsx')\n",
    "sheet_names = ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']\n",
    "for sheet in sheet_names:\n",
    "    df_tmp = pd.read_excel(file, sheet_name=sheet)\n",
    "    df = df.append(df_tmp)\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hepler functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functino calculates the MAPE of two seres. It receives a dataframe that has two columns: actual and forecasted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "def get_mape(df, ticker, pred_tag, test_count=126):\n",
    "    df = df.dropna(how='any')\n",
    "    test_true = df.iloc[-test_count:][ticker]\n",
    "    test_pred = df.iloc[-test_count:][f'{ticker}_{pred_tag}']\n",
    "    mapel = mean_absolute_percentage_error(\n",
    "        test_true, test_pred\n",
    "    ) \n",
    "    return mapel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function Will convert the arabic glyphs to standard farsi glyphs. This will be helpful while looking Tehran50 tickers up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groom(s):\n",
    "    s = s.replace('ي', 'ی')\n",
    "    s = s.replace('ك', 'ک')\n",
    "    return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explain the code in 8 steps. The starting point of each step is commented in the code by the corresponding number:\n",
    "\n",
    "1. We Will save all the plots in the `./preds_vecm/{index_name}/` directory. We will remove and recreate the directory each time we run the code.\n",
    "2. We write a for loop that itterates over four indices: 'Dow Jones', 'CAC 40', 'Dax', 'Teh50'\n",
    "3. We get the list of tickers that are cointegrated from the previous project.\n",
    "4. We get the price of all the cointegrated tickers in each index. We split the data into train and test.\n",
    "5. **One-Step ahead forecast**: For each day in the test period, we consider all leading days as the training set and build a VECM model based on the training data and forecast one step ahead.\n",
    "6. **Dynamic Multi-Step ahead forecast**: We build a VECM model based on the first 521 days and forecast the 126 days ahead. VECM class uses Dynamic forecasting by default.\n",
    "7. We plot the the actual values in conjunction with the forecasted values in one graph and save them in `./preds_vecm/{index_name}/` directory.\n",
    "8. We save the mape value of our forecast in a dictinoary. The will later be used to comapre with Neural Network's forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "import os\n",
    "# 1\n",
    "PATH = r'./preds_vecm/'\n",
    "if os.path.exists(PATH):\n",
    "    shutil.rmtree(PATH)\n",
    "os.makedirs(PATH)\n",
    "    \n",
    "errors = []\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 2\n",
    "for indice in ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']:\n",
    "    print(indice, '>>', flush=True)\n",
    "\n",
    "    # Creating the required directories to save the plots\n",
    "    PATH = rf'./preds_vecm/{indice}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    # 3\n",
    "    df1 = df[df['indice']==indice]\n",
    "    tickers = stock_list.get_stock_list(index=indice)\n",
    "    isTSE = (indice == 'Teh50')\n",
    "    if isTSE:\n",
    "        tickers = [groom(x) for x in tickers]\n",
    "    data_historical = stock_prices.get_prices(tickers, isTSE)\n",
    "\n",
    "\n",
    "    for i in range(df1.shape[0]):\n",
    "        ticker1, ticker2, indice = df1.iloc[i]\n",
    "\n",
    "        # 4\n",
    "        data_historical1 = data_historical[[ticker1, ticker2]]\n",
    "        data_historical1 = data_historical1.dropna(how='all')\n",
    "        data = data_historical1[-interval:]\n",
    "        limitPer = len(data) * .85\n",
    "        data = data.dropna(thresh=limitPer, axis=1)\n",
    "        data = np.log(data)\n",
    "        data = data.dropna(how='any')\n",
    "        data_train = data[:-testsmpl]\n",
    "        data_test = data[-testsmpl:]\n",
    "        df_train = data_train.copy()\n",
    "\n",
    "        # 5\n",
    "        # 1Step\n",
    "        df_train = data_train.copy()\n",
    "        is_cointegrated, lag_order, rank = get_cointegration_params(df_train)\n",
    "        if not is_cointegrated:\n",
    "            continue\n",
    "\n",
    "        df_predictions = pd.DataFrame()\n",
    "        for d in range(testsmpl):\n",
    "            model = VECM(df_train, deterministic=\"ci\",\n",
    "                    k_ar_diff=lag_order,\n",
    "                    coint_rank=rank)\n",
    "\n",
    "            vecm_res = model.fit()\n",
    "            pred = vecm_res.predict(steps=1)\n",
    "            data.loc[data_test.iloc[d].name, f'{ticker1}_1step'] = pred[0][0]\n",
    "            data.loc[data_test.iloc[d].name, f'{ticker2}_1step'] = pred[0][1]\n",
    "            df_train = df_train.append(data_test.iloc[d])\n",
    "        \n",
    "        # 6\n",
    "        # Multistep\n",
    "        df_train = data_train.copy()\n",
    "        is_cointegrated, lag_order, rank = get_cointegration_params(df_train)\n",
    "        if not is_cointegrated:\n",
    "            continue\n",
    "        \n",
    "        model = VECM(df_train, deterministic=\"ci\",\n",
    "                    k_ar_diff=lag_order,\n",
    "                    coint_rank=rank)\n",
    "        vecm_res = model.fit()\n",
    "        preds = vecm_res.predict(steps=testsmpl)\n",
    "        for i, pred in enumerate(preds):\n",
    "            data.loc[data_test.iloc[i].name, f'{ticker1}_multi'] = pred[0]\n",
    "            data.loc[data_test.iloc[i].name, f'{ticker2}_multi'] = pred[1]\n",
    "\n",
    "        # 7\n",
    "        # Plotting\n",
    "        ax = data.plot(figsize=(15, 8));\n",
    "        ax.figure.savefig(rf'./preds_vecm/{indice}/{ticker1}_{ticker2}.png');\n",
    "        plt.close()\n",
    "\n",
    "        # 8\n",
    "        # mape\n",
    "        for ticker, tag in list(itertools.product([ticker1, ticker2], ['1step', 'multi'])):\n",
    "            mape=get_mape(data, ticker=ticker, pred_tag=tag, test_count=testsmpl)\n",
    "            errors.append({\n",
    "                'tag': f'vecm_{tag}',\n",
    "                'ticker': ticker,\n",
    "                'pair': ticker2 if ticker==ticker1 else ticker1,\n",
    "                'mape': mape*100,\n",
    "                'indice': indice\n",
    "            })\n",
    "\n",
    "filename = rf'./vecm_mape.xlsx'\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "df_errors = pd.DataFrame(errors)\n",
    "for index, group_df in df_errors.groupby(\"indice\"):   \n",
    "    group_df.to_excel(writer, sheet_name=str(index),index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
