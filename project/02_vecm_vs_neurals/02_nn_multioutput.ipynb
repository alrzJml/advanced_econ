{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importig Two helper functions from `./helper_functions`:\n",
    "\n",
    "- `stock_list`: This functions gets an index name (e.g. 'Dow Jones', 'CAC 40', 'DAX', 'Teh50') and returns the list of stocks in that index.\n",
    "\n",
    "- `stock_prices`: This functions recieves a list of tickers and returns a pandas dataframe containing prices of the corresponding tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import stock_prices, stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Fucntions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the 521 trailing days of prices series. 126 last days will be the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 521\n",
    "testsmpl=126"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function recives a dataframe and returns the lag matrix of its first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagmat(df, T=115) -> (np.array, np.array):\n",
    "    X = []\n",
    "    Y = []\n",
    "    tag = df.columns[0]\n",
    "    series = df[tag].to_numpy()[:]\n",
    "    for t in range(len(series) - T):\n",
    "        x = series[t:t+T]\n",
    "        X.append(x)\n",
    "        y = series[t+T]\n",
    "        Y.append(y)\n",
    "\n",
    "    X = np.array(X).reshape(-1 ,T)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function Will convert the arabic glyphs to standard farsi glyphs. This will be helpful while looking Tehran50 tickers up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groom(s):\n",
    "    s = s.replace('ي', 'ی')\n",
    "    s = s.replace('ك', 'ک')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functino calculates the MAPE of two seres. It receives a dataframe that has two columns: actual and forecasted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "def get_mape(df, ticker, pred_tag, test_count=126):\n",
    "    df = df.dropna(how='any')\n",
    "    test_true = df.iloc[-test_count:][ticker]\n",
    "    test_pred = df.iloc[-test_count:][f'{ticker}_{pred_tag}']\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        test_true, test_pred\n",
    "    ) \n",
    "    return mape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because running this code may take a long time, we save the result of each model when it's done. This functino opens and excel file and append the last calculated mape values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def write_to_excel(errors):\n",
    "    filename = rf'./nn_mape.xlsx'\n",
    "    if not os.path.exists(filename):\n",
    "        writer = pd.ExcelWriter(filename, engine='openpyxl', mode='w')\n",
    "    else:\n",
    "        writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "    df_errors = pd.DataFrame(errors)\n",
    "    for index, group_df in df_errors.groupby(\"indice\"):   \n",
    "        group_df.to_excel(writer, sheet_name=str(index),index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the list of cointegrated tickers from the output of the previous project (i.e. 01_pair_trading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices = pd.DataFrame()\n",
    "file = pd.ExcelFile('../01_pair_trading/pairs_2023-01-15.xlsx')\n",
    "sheet_names = ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']\n",
    "for sheet in sheet_names:\n",
    "    df_tmp = pd.read_excel(file, sheet_name=sheet)\n",
    "    df_indices = df_indices.append(df_tmp)\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explain the code in 7 steps. The starting point of each step is commented in the code by the corresponding number:\n",
    "\n",
    "1. We Will save all the plots in the `./preds_nn/{index_name}/` directory. We will remove and recreate the directory each time we run the code.\n",
    "2. We write a for loop that itterates over four indices: 'Dow Jones', 'CAC 40', 'Dax', 'Teh50'\n",
    "3. We get the list of tickers that are cointegrated from the previous project.\n",
    "4. We get the price of all the cointegrated tickers in each index. We split the data into train and test.\n",
    "5. **Dynamic Multi-Step ahead forecast**: We build a MLPRegressor model based on the first 521 days and forecast the 126 days ahead. MLPRegressor class uses Dynamic forecasting by default.\n",
    "6. **One-Step ahead forecast**: For each day in the test period, we consider all leading days as the training set and build a MLPRegressor model based on the training data and forecast one step ahead.\n",
    "7. We plot the the actual values in conjunction with the forecasted values in one graph and save them in `./preds_vecm/{index_name}/` directory.\n",
    "8. We save the mape value of our forecast in a dictinoary. The will later be used to comapre with VECM's forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dow Jones >>\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,CAC 40 >>\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OCBI: No data found, symbol may be delisted\n",
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,Dax >>\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AZSEY: No data found, symbol may be delisted\n",
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,Teh50 >>\n",
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "import os\n",
    "# 1\n",
    "PATH = r'./preds_nn'\n",
    "if os.path.exists(PATH):\n",
    "    shutil.rmtree(PATH)\n",
    "if os.path.exists(rf'./nn_mape.xlsx'):\n",
    "    os.remove(rf'./nn_mape.xlsx')\n",
    "os.makedirs(PATH)\n",
    "    \n",
    "errors = []\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 2\n",
    "for indice in ['Dow Jones', 'CAC 40', 'Dax', 'Teh50']:\n",
    "    try:\n",
    "        df_dones = pd.read_excel('nn_mape2.xlsx', sheet_name=indice)\n",
    "    except:\n",
    "        df_dones = pd.DataFrame([], columns=['tag', 'ticker', 'pair', 'mape', 'indice'])\n",
    "\n",
    "    print(indice, '>>', flush=True)\n",
    "    # Creating the required directories to save the plots\n",
    "    PATH = rf'./preds_nn/{indice}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    # 3\n",
    "    df1 = df_indices[df_indices['indice']==indice]\n",
    "    tickers = stock_list.get_stock_list(index=indice)\n",
    "    isTSE = (indice == 'Teh50')\n",
    "    if isTSE:\n",
    "        tickers = [groom(x) for x in tickers]\n",
    "    data_historical = stock_prices.get_prices(tickers, isTSE)\n",
    "\n",
    "    for i in range(df1.shape[0]):\n",
    "        print(f'{i}', end=',', flush=True)\n",
    "        ticker1, ticker2, indice = df1.iloc[i]\n",
    "\n",
    "        if df_dones[(\n",
    "            (df_dones['ticker']==ticker1) \n",
    "            & (df_dones['pair']==ticker2)\n",
    "        )].shape[0] > 0:\n",
    "            continue\n",
    "        \n",
    "        # 4\n",
    "        data_historical1 = data_historical[[ticker1, ticker2]]\n",
    "        data_historical1 = data_historical1.dropna(how='all')\n",
    "        data = data_historical1[-interval:]\n",
    "        limitPer = len(data) * .85\n",
    "        data = data.dropna(thresh=limitPer, axis=1)\n",
    "        data = np.log(data)\n",
    "        data = data.dropna(how='any')\n",
    "        X1, Y1 = lagmat(data[[ticker1]])\n",
    "        X2, Y2 = lagmat(data[[ticker2]])\n",
    "        Y1 = np.expand_dims(Y1, axis=1)\n",
    "        Y2 = np.expand_dims(Y2, axis=1)\n",
    "        X = np.hstack((X1, X2))\n",
    "        Y = np.hstack((Y1, Y2))\n",
    "        X_train, X_test = X[:-testsmpl], X[-testsmpl:] \n",
    "        Y_train, Y_test = Y[:-testsmpl], Y[-testsmpl:] \n",
    "        data_train = data[:-testsmpl]\n",
    "        data_test = data[-testsmpl:]\n",
    "        df_train = data_train.copy()\n",
    "        df_data = pd.DataFrame([], columns=[ticker1, ticker2])\n",
    "        df_preds = pd.DataFrame([], columns=[f'{ticker1}_multi', f'{ticker2}_multi',\n",
    "        f'{ticker1}_1step', f'{ticker2}_1step'])\n",
    "        data[df_preds.columns] = np.nan\n",
    "\n",
    "        # 5\n",
    "        preds_regr = MultiOutputRegressor(MLPRegressor()).fit(X_train, Y_train)\n",
    "        forecast_multistep = preds_regr.predict(X_test)\n",
    "        df_preds[[f'{ticker1}_multi', f'{ticker2}_multi']] = forecast_multistep\n",
    "\n",
    "        # 6\n",
    "        preds_1step = np.ndarray(shape=(0,2))\n",
    "        X_train_1step = X_train.copy()\n",
    "        Y_train_1step = Y_train.copy()\n",
    "        preds_regr = MultiOutputRegressor(MLPRegressor()).fit(X_train, Y_train)\n",
    "        for i in range(X_test.shape[0]):\n",
    "            forecast_1step = preds_regr.predict([X_train_1step[-1]])\n",
    "            preds_1step = np.vstack([preds_1step, forecast_1step])\n",
    "\n",
    "            X_train_1step = np.vstack((X_train_1step, X_test[i]))\n",
    "            Y_train_1step = np.vstack([Y_train_1step, Y_test[i]])\n",
    "        df_preds[[f'{ticker1}_1step', f'{ticker2}_1step']] = preds_1step\n",
    "        data.iloc[-testsmpl:, 2:] = df_preds\n",
    "\n",
    "        # 7\n",
    "        # Plotting\n",
    "        ax = data.plot(figsize=(15, 8));\n",
    "        ax.figure.savefig(rf'./preds_nn/{indice}/{ticker1}_{ticker2}.png');\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # 8\n",
    "        # mape\n",
    "        errors = []\n",
    "        for ticker, tag in list(itertools.product([ticker1, ticker2], ['1step', 'multi'])):\n",
    "            mape=get_mape(data, ticker=ticker, pred_tag=tag)\n",
    "            errors.append({\n",
    "                'tag': f'nn_{tag}',\n",
    "                'ticker': ticker,\n",
    "                'pair': ticker2 if ticker==ticker1 else ticker1,\n",
    "                'mape': mape*100,\n",
    "                'indice': indice\n",
    "            })\n",
    "        df_dones = df_dones.append(errors, ignore_index=True)\n",
    "        write_to_excel(df_dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
